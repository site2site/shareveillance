## October 24, 2013

Critiques:

* ![Critique 1](https://raw.github.com/site2site/shareveillance/master/images/Critique_1.JPG)

-Connecting with other Studio-X sites
-Moving outside enclosed Studio-X space and into urban fabric
-Political dimensions
-Using CV to recognize found objects and produce new symbologies/relationships

* ![Critique 2](https://raw.github.com/site2site/shareveillance/master/images/Critique_2.JPG)

-Connecting Studio-X content with other databases, particularly social media (eg. Tumblr, Instagram, Twitter)
-Automatic search engine (images "like this")
-User participation (pin-up board)

* ![Critique 3](https://raw.github.com/site2site/shareveillance/master/images/Critique_3.JPG)

-Camera as collaborator (embracing the false positives to read new meanings in space)
-Creating an archive/database based on a growing taxonomy of user-created CV-readable shapes/symbols

Hackathon Plan:

* ![Hackathon plan](https://raw.github.com/site2site/shareveillance/master/images/Hackathon_Plan.JPG)

## September 28, 2013

Your project allows users to tag physical objects in a video feed streamed to the web, turning them into unique click targets. These targets can be produced over time, providing the directors of Studio-X with a new tool to curate their online communications through physical space.

This requires:


1.	An interface for the Studio-X directors to input the things they want these physical click targets to link to

2.	A means of creating unique tags

3.	A means of reading these tags from an image

4.	An installation strategy - which part of the space will you capture?

5.	A user interface design


Your immediate step is to talk to Nicky, Carlos and Benedict in order to find an installation strategy - do this as soon as possible. Figure out from them what part of the space they are comfortable exposing online, and which is the best place to capture that they will actually engage with the product you are building.

You may not have all parts working by the hackathon, but you need #3, #4 and #5 at a minimum. You can work with a finite number of predesigned tags to start, with the idea that ultimately, the directors can make their own tags over time.



## September 20, 2013

The Raspberry Pi has an HDMI output port, so it's quite easy to connect it to a projector. You'll want to look into video codecs and other Linux-based solutions for dealing with video and image content. For instance, check out http://www.ffmpeg.org/ and the Raspberry Pi camera. Do some Google sleuthing on streaming video with a Raspberry Pi: for instance, http://blog.tkjelectronics.dk/2013/06/how-to-stream-video-and-audio-from-a-raspberry-pi-with-no-latency/.

The Raspberry Pi camera has a number of built-in filters that you'll want to Google, as you'll likely be using it (it's HD, small and cheap - $25 - and I bought a few for the class already). You should also search around Github for anything to do with video streaming and image processing. If you're into computer vision, like facial recognition, check out https://github.com/peterbraden/node-opencv. If you're into making animated GIFs, or superimposing images, or other Photoshop-like features, check out https://github.com/rsms/node-imagemagick.

You'll also need to have a stance on what kind of content you're projecting and why. The notion of personal space and sharing came up in the discussion, so we will want to know if this is what you're taking on, or if you're going another way. If you are working with cameras and projectors, you MUST have a stance on surveillance. In the Glenn Greenwald/Eric Snowden micro-era we are in, this cannot be ignored, and it is too good of an opportunity to spark a debate to go unheeded.
